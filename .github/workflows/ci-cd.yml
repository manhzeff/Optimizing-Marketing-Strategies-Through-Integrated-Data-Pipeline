# .github/workflows/ci-cd.yml
name: CI-CD Pipeline

on:
  push:
    branches: [ "dev-manh" ]
  pull_request:
    branches: [ "main" ]

jobs:
  end_to_end_pipeline:
    runs-on: ubuntu-latest

    steps:
      # 1. Check out mã nguồn
      - name: Check out repo
        uses: actions/checkout@v2

      # 2. Thiết lập Docker Buildx (nếu cần build image)
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v1

      # -----------------------------------------------------------
      # 3. Khởi động Airflow (batch) & Trigger DAG qua REST API
      # -----------------------------------------------------------
      - name: Start Airflow via Docker Compose
        run: |
          cd sources/batch_processing/airflow/dag-airflow
          docker compose up -d
          echo "Chờ Airflow khởi động..."
          sleep 30  # Tùy chỉnh nếu Airflow cần nhiều thời gian hơn

      - name: Trigger Airflow DAG
        run: |
          echo "Gọi Airflow REST API để trigger DAG"
          # Giả sử: user=airflow, pass=airflow, dag_id=my_dag_id
          # Lưu ý: thay 'my_dag_id' bằng tên DAG thực tế
          curl -u "airflow:airflow" \
               -X POST "http://localhost:8080/api/v1/dags/data_ingestion_aws_project/dagRuns" \
               -H "Content-Type: application/json" \
               -d '{ 
                     "conf": {}, 
                     "dag_run_id": "ci_cd_trigger_1" 
                   }'
          echo "Đợi 100 giây để DAG chạy"
          sleep 100



      - name: Monitor Airflow DAG
        run: |
          echo "Monitoring DAG execution status..."
          until [ "$(curl -u airflow:airflow -s \
            -X GET "http://localhost:8080/api/v1/dags/data_ingestion_aws_project/dagRuns/ci_cd_trigger" | jq -r '.state')" = "success" ]; do
            echo "DAG is still running..."
            sleep 10
          done
          echo "DAG execution completed successfully."
          

      - name: Teardown Airflow
        run: |
          cd sources/batch_processing/airflow/dag-airflow
          docker compose down

      # -----------------------------------------------------------
      # 4. Khởi động Kafka & Chạy producer + consumer
      # -----------------------------------------------------------
      - name: Start Kafka
        run: |
          cd sources/stream_processing
          docker compose up -d
          echo "Chờ Kafka khởi động..."
          sleep 15

      - name: Run Kafka Producer
        run: |
          cd sources/stream_processing
          python producer.py

      - name: Run Kafka Consumer
        run: |
          cd sources/stream_processing
          python consumer.py

      - name: Teardown Kafka
        run: |
          cd sources/stream_processing
          docker compose down

      # -----------------------------------------------------------
      # 6. Cài dbt & chạy dbt run (DWH & Data Mart)
      # -----------------------------------------------------------
      - name: Install dbt
        run: |
          pip install dbt-core dbt-snowflake
          # Hoặc dbt-bigquery, dbt-postgres... tùy DWH

      - name: dbt run for marketing_campaign_dwh
        run: |
          cd sources/batch_processing/dbt/marketing_campaign_dwh
          dbt deps
          dbt run
          dbt test

      - name: dbt run for marketing_datamart
        run: |
          cd sources/batch_processing/dbt/marketing_datamart
          dbt deps
          dbt run
          dbt test
